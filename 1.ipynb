{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNeedInstall = False\n",
    "if isNeedInstall:\n",
    "    import subprocess\n",
    "    import sys\n",
    "\n",
    "    def install(package):\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "    install(\"pyspark\")\n",
    "    install(\"psutil\")\n",
    "    install(\"nbconvert\")\n",
    "    install(\"ipykernel\")\n",
    "    install(\"py4j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to True to run the program on full dataset\n",
    "isProd = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_cores = 2\n",
    "memory_gb = 4\n",
    "# Create a configuration object and\n",
    "# set the name of the application\n",
    "conf = (\n",
    "    SparkConf()\n",
    "        .setAppName(\"mandarin\")\n",
    "        .setMaster('local[{}]'.format(number_cores))\n",
    "        .set('spark.driver.memory', '{}g'.format(memory_gb))\n",
    ")\n",
    "# Create a Spark Context object\n",
    "sc = SparkContext.getOrCreate()#(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input file\n",
    "if isProd:\n",
    "    if not os.path.exists('input/Reviews.csv'):\n",
    "        sc.stop()\n",
    "        raise Exception(\"\"\"\n",
    "            Download the 'Reviews.csv' file from https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews\n",
    "            and put it in 'input' folder\n",
    "        \"\"\")\n",
    "    else:\n",
    "        inputRdd = sc.textFile(\"input/Reviews.csv\")\n",
    "else:\n",
    "    inputRdd = sc.textFile(\"input/Sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the header\n",
    "filteredInput = inputRdd.filter(lambda line: line.startswith(\"Id,\") == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. З вхідного датасету створити RDD, що містить пару (tuple) UserId та список всіх ProductId для всіх продуктів, які купував/ревьював цей юзер. В списку повинні бути лише унікальні продукти (ProductId  для одного юзера не повинні повторюватись). Наприклад:\n",
    "(\"A1\", [\"B1\", \"B2\", \"B5\"])\n",
    "(\"A2\", [\"B1\", \"B3\", \"B5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A2', 'B1'],\n",
       " ['A4', 'B1'],\n",
       " ['A5', 'B1'],\n",
       " ['A1', 'B2'],\n",
       " ['A2', 'B3'],\n",
       " ['A3', 'B3'],\n",
       " ['A4', 'B3'],\n",
       " ['A5', 'B3'],\n",
       " ['A4', 'B4'],\n",
       " ['A2', 'B5'],\n",
       " ['A4', 'B5'],\n",
       " ['A2', 'B1'],\n",
       " ['A4', 'B5'],\n",
       " ['A5', 'B5']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userProductMap = filteredInput.map(lambda x: x.split(\",\")[2] + \",\" + x.split(\",\")[1]).map(lambda x: x.split(\",\"))\n",
    "userProductMap.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A1', {'B2'}),\n",
       " ('A2', {'B1', 'B3', 'B5'}),\n",
       " ('A3', {'B3'}),\n",
       " ('A4', {'B1', 'B3', 'B4', 'B5'}),\n",
       " ('A5', {'B1', 'B3', 'B5'})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_value = set()\n",
    "\n",
    "def seq_op(x,y):\n",
    "    x.add(y)\n",
    "    return x\n",
    "\n",
    "def comb_op(x,y):\n",
    "    return x.union(y)\n",
    "\n",
    "userProducts = userProductMap.aggregateByKey(zero_value, seq_op, comb_op).sortByKey()\n",
    "userProducts.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Маючи списки продуктів для кожного юзера, отримати всі пари продуктів які він міг купувати разом. Для кожної такої пари створити tuple де першим елементом є пара, другим число 1. Наприклад для попереднього списку:\n",
    "(\"B1,B2\", 1)\n",
    "(\"B1,B5\", 1)\n",
    "(\"B2,B5\", 1)\n",
    "(\"B1,B3\", 1)\n",
    "(\"B1,B5\", 1)\n",
    "(\"B3,B5\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'B5', 'B1', 'B3'}, {'B5', 'B1', 'B3', 'B4'}, {'B5', 'B1', 'B3'}]\n"
     ]
    }
   ],
   "source": [
    "productPairsMap = list(userProducts.reduceByKey(lambda a,b: b.lookup(a)).map(lambda r: r[1]).filter(lambda x: len(x)>1).collect())\n",
    "print(productPairsMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B5B1', 'B1B3', 'B5B1', 'B1B3', 'B3B4', 'B5B1', 'B1B3']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j = 0 \n",
    "tupleProduct = []\n",
    "tempList = []\n",
    "for x in productPairsMap:\n",
    "    tempList.append(list(x))\n",
    "while i < len(tempList):\n",
    "    while j<len(tempList[i])-1:\n",
    "        tupleProduct.append(tempList[i][j]+tempList[i][j+1])\n",
    "        j+=1\n",
    "    i+=1\n",
    "    j=0\n",
    "print(tupleProduct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B5B1', 1),\n",
       " ('B1B3', 1),\n",
       " ('B5B1', 1),\n",
       " ('B1B3', 1),\n",
       " ('B3B4', 1),\n",
       " ('B5B1', 1),\n",
       " ('B1B3', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nextStep = sc.parallelize(tupleProduct)\n",
    "tupleProductWithOne = nextStep.map(lambda x: (x,1))\n",
    "tupleProductWithOne.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Підрахувати кількість всіх пар продуктів, відсортувати їх за кількістю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B5B1', 3), ('B1B3', 3), ('B3B4', 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allTupleProd = list(tupleProductWithOne.countByKey().items())\n",
    "tempProd = sc.parallelize(allTupleProd)\n",
    "productPairsCounts = tempProd.sortBy(lambda x: -x[1])\n",
    "productPairsCounts.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Взяти лише перші 10 пар продуктів та їх кількість. Зберегти в файл. Наприклад:\n",
    "(\"B1,B5\", 23495)\n",
    "(\"B2,B5\", 3340)\n",
    "(\"B3,B5\", 217)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B5B1', 3), ('B1B3', 3), ('B3B4', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = productPairsCounts.zipWithIndex().filter(lambda vi: vi[1] < 10).keys()\n",
    "result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = 'output/first_output'\n",
    "if os.path.exists(outpath) and os.path.isdir(outpath):\n",
    "    shutil.rmtree(outpath)\n",
    "\n",
    "result.saveAsTextFile(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop the Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98150487c3ea4eb7b8eab087c675bf955334d0813044dccb8841940644ac4c2f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
